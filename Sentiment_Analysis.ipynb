{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGM5gO8S4U6q",
        "colab_type": "code",
        "outputId": "1921fc4d-44a7-4573-97cc-cde28258cebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPool2D\n",
        "from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueANWt0m4aNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvMTV0Rw4nnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive -o nonempty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLrrggZf4r6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9LKWHb44U60",
        "colab_type": "code",
        "outputId": "1e332a3c-035c-48c6-cbb5-055583c7d782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#data_train = pd.read_csv('v1/Preprocessed_using_translator_train.csv')\n",
        "data_train = pd.read_csv('Preprocessed_using_translator_train.csv')\n",
        "data_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doxRjNRp4U64",
        "colab_type": "code",
        "outputId": "4af0968c-6b60-46cf-de10-4610cb192623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#data_test= pd.read_csv(\"v1/Preprocessed_using_translator_test.csv\")\n",
        "data_test= pd.read_csv(\"Preprocessed_using_translator_test.csv\")\n",
        "data_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYjpQ5EX4U6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train[\"text\"] = data_train[\"text\"].apply(str)\n",
        "data_test[\"text\"] = data_test[\"text\"].apply(str)\n",
        "ylabels = pd.get_dummies(data_train.iloc[:,2].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB1g4sHs4U7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = 2000\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(data_train[\"text\"].values)\n",
        "sequences = tokenizer.texts_to_sequences(data_train[\"text\"].values)\n",
        "data = pad_sequences(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grHHUSh04U7F",
        "colab_type": "code",
        "outputId": "379c9a9d-5d66-4167-a93a-637d2097b524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "xtrain, xval, ytrain, yval = train_test_split(data, ylabels, test_size=0.10, random_state=960)\n",
        "print(xtrain.shape, xval.shape, ytrain.shape, yval.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(360000, 976) (40000, 976) (360000, 3) (40000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FVj-P2E4U7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = Sequential()\n",
        "#model.add(Conv1D(batch_size=20, input_shape=(330, 1), filters=100, kernel_size=5, strides=1, activation='relu', kernel_regularizer=regularizers.l2(0.01), use_bias=True))\n",
        "#model.add(Flatten())\n",
        "#model.add(MaxPooling1D(pool_size=10))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(Dense(units=3, activation='softmax', use_bias=True))\n",
        "#model.add(Flatten())\n",
        "#myopti = optimizers.SGD(lr=0.01, momentum=0.9, decay=0.001)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=myopti, metrics=['accuracy'])\n",
        "#st = time.time()\n",
        "#history = model.fit(datatemp, ylabels, validation_split=0.05, epochs=3, verbose=1, batch_size=20)\n",
        "#en = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_Fs02sN4U7N",
        "colab_type": "code",
        "outputId": "de16160a-663d-49db-b77d-84920204a7e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "sequence_length = data.shape[1]\n",
        "embedding_dim = 76\n",
        "num_filters = 32\n",
        "filter_sizes = [33, 33, 33]\n",
        "drop = 0.2\n",
        "\n",
        "inputs = Input(shape=(sequence_length,), dtype='int32')\n",
        "embedding = Embedding(input_dim=vocabulary_size, output_dim=embedding_dim, input_length=sequence_length)(inputs)\n",
        "reshape = Reshape((sequence_length,embedding_dim,1))(embedding)\n",
        "\n",
        "c0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "c1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "c2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "\n",
        "DP0 = MaxPool2D(pool_size=(sequence_length - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(c0)\n",
        "DP1 = MaxPool2D(pool_size=(sequence_length - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(c1)\n",
        "DP2 = MaxPool2D(pool_size=(sequence_length - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(c2)\n",
        "\n",
        "CT = Concatenate(axis=1)([DP0, DP1, DP2])\n",
        "\n",
        "flatten = Flatten()(CT)\n",
        "dropout = Dropout(drop)(flatten)\n",
        "output = Dense(units=3, activation='softmax')(dropout)\n",
        "\n",
        "batch_size=32\n",
        "epochs = 10\n",
        "\n",
        "model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "checkpoint = ModelCheckpoint('weights.{epoch:03d}-{val_acc:.4f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
        "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "st = time.time()\n",
        "model.fit(xtrain, ytrain, batch_size=batch_size, epochs=epochs, verbose=1, callbacks=[checkpoint], validation_data=(xval, yval))  # starts training\n",
        "en = time.time()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 360000 samples, validate on 40000 samples\n",
            "Epoch 1/3\n",
            " 20128/360000 [>.............................] - ETA: 12:23 - loss: 0.5249 - acc: 0.7531"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 51456/360000 [===>..........................] - ETA: 10:56 - loss: 0.4500 - acc: 0.7965"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85472/360000 [======>.......................] - ETA: 9:39 - loss: 0.3813 - acc: 0.8303"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "117984/360000 [========>.....................] - ETA: 8:29 - loss: 0.3403 - acc: 0.8505"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "150368/360000 [===========>..................] - ETA: 7:20 - loss: 0.3141 - acc: 0.8630"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "183296/360000 [==============>...............] - ETA: 6:10 - loss: 0.2954 - acc: 0.8720"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "216384/360000 [=================>............] - ETA: 5:01 - loss: 0.2821 - acc: 0.8785"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "249312/360000 [===================>..........] - ETA: 3:51 - loss: 0.2713 - acc: 0.8836"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "282336/360000 [======================>.......] - ETA: 2:42 - loss: 0.2625 - acc: 0.8878"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "315872/360000 [=========================>....] - ETA: 1:32 - loss: 0.2552 - acc: 0.8912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "348672/360000 [============================>.] - ETA: 23s - loss: 0.2492 - acc: 0.8941"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "360000/360000 [==============================] - 782s 2ms/step - loss: 0.2475 - acc: 0.8949 - val_loss: 0.1846 - val_acc: 0.9242\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.92423, saving model to weights.001-0.9242.hdf5\n",
            "Epoch 2/3\n",
            "  5728/360000 [..............................] - ETA: 12:29 - loss: 0.1813 - acc: 0.9257"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 38080/360000 [==>...........................] - ETA: 11:13 - loss: 0.1847 - acc: 0.9234"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70848/360000 [====>.........................] - ETA: 10:04 - loss: 0.1850 - acc: 0.9241"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "103968/360000 [=======>......................] - ETA: 8:54 - loss: 0.1834 - acc: 0.9250"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "137216/360000 [==========>...................] - ETA: 7:45 - loss: 0.1819 - acc: 0.9257"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170784/360000 [=============>................] - ETA: 6:35 - loss: 0.1813 - acc: 0.9262"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "203904/360000 [===============>..............] - ETA: 5:25 - loss: 0.1813 - acc: 0.9263"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "237664/360000 [==================>...........] - ETA: 4:15 - loss: 0.1812 - acc: 0.9264"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "271296/360000 [=====================>........] - ETA: 3:05 - loss: 0.1806 - acc: 0.9266"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "304480/360000 [========================>.....] - ETA: 1:55 - loss: 0.1801 - acc: 0.9268"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "337248/360000 [===========================>..] - ETA: 47s - loss: 0.1795 - acc: 0.9272"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "360000/360000 [==============================] - 779s 2ms/step - loss: 0.1792 - acc: 0.9273 - val_loss: 0.1722 - val_acc: 0.9304\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.92423 to 0.93037, saving model to weights.002-0.9304.hdf5\n",
            "Epoch 3/3\n",
            "  2912/360000 [..............................] - ETA: 12:53 - loss: 0.1636 - acc: 0.9375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35648/360000 [=>............................] - ETA: 11:16 - loss: 0.1628 - acc: 0.9351"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68160/360000 [====>.........................] - ETA: 10:08 - loss: 0.1655 - acc: 0.9339"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100640/360000 [=======>......................] - ETA: 9:00 - loss: 0.1656 - acc: 0.9336"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "133824/360000 [==========>...................] - ETA: 7:51 - loss: 0.1656 - acc: 0.9338"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "166528/360000 [============>.................] - ETA: 6:43 - loss: 0.1651 - acc: 0.9342"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "199168/360000 [===============>..............] - ETA: 5:35 - loss: 0.1646 - acc: 0.9344"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "231616/360000 [==================>...........] - ETA: 4:27 - loss: 0.1645 - acc: 0.9345"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "265568/360000 [=====================>........] - ETA: 3:16 - loss: 0.1643 - acc: 0.9345"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "298048/360000 [=======================>......] - ETA: 2:09 - loss: 0.1641 - acc: 0.9346"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "331680/360000 [==========================>...] - ETA: 58s - loss: 0.1639 - acc: 0.9345"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "360000/360000 [==============================] - 777s 2ms/step - loss: 0.1638 - acc: 0.9347 - val_loss: 0.1636 - val_acc: 0.9348\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.93037 to 0.93478, saving model to weights.003-0.9348.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cn3m0T14U7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}